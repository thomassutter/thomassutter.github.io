---
title: "On the Limitations of Multimodal VAEs"
collection: publications
permalink: /publication/2015-10-01-On the Limitations of Multimodal VAEs
excerpt: 'Multimodal variational autoencoders (VAEs) have shown promise as efficient generative models for weakly-supervised data. Yet, despite their advantage of weak supervision, they exhibit a gap in generative quality compared to unimodal VAEs, which are completely unsupervised. In an attempt to explain this gap, we uncover a fundamental limitation that applies to a large family of mixture-based multimodal VAEs. We prove that the sub-sampling of modalities enforces an undesirable upper bound on the multimodal ELBO and thereby limits the generative quality of the respective models. Empirically, we showcase the generative quality gap on both synthetic and real data and present the tradeoffs between different variants of multimodal VAEs. We find that none of the existing approaches fulfills all desired criteria of an effective multimodal generative model when applied on more complex datasets than those used in previous benchmarks. In summary, we identify, formalize, and validate fundamental limitations of VAE-based approaches for modeling weakly-supervised data and discuss implications for real-world applications.'
date: 2015-10-01
venue: 'ICLR 2022'
paperurl: 'https://arxiv.org/abs/2110.04121'
citation: 'I Daunhawer, TM Suttter, K Chin-Cheong, E Palumbo, JE Vogt. (2022). &quot;On the limitations of multimodal VAEs.&quot; <i>ICLR 2022</i>. 1(3).'
---
Multimodal variational autoencoders (VAEs) have shown promise as efficient generative models for weakly-supervised data. Yet, despite their advantage of weak supervision, they exhibit a gap in generative quality compared to unimodal VAEs, which are completely unsupervised. In an attempt to explain this gap, we uncover a fundamental limitation that applies to a large family of mixture-based multimodal VAEs. We prove that the sub-sampling of modalities enforces an undesirable upper bound on the multimodal ELBO and thereby limits the generative quality of the respective models. Empirically, we showcase the generative quality gap on both synthetic and real data and present the tradeoffs between different variants of multimodal VAEs. We find that none of the existing approaches fulfills all desired criteria of an effective multimodal generative model when applied on more complex datasets than those used in previous benchmarks. In summary, we identify, formalize, and validate fundamental limitations of VAE-based approaches for modeling weakly-supervised data and discuss implications for real-world applications.

[Download paper here](https://arxiv.org/abs/2110.04121)

Recommended citation: I Daunhawer, TM Suttter, K Chin-Cheong, E Palumbo, JE Vogt. (2022). "On the limitations of multimodal VAEs." <i>ICLR 2022</i>. 1(3).