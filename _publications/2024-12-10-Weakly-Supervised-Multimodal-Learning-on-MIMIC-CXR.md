---
title: "Weakly-Supervised Multimodal Learning on MIMIC-CXR"
collection: publications
permalink: /publication/2024-12-10-Weakly-Supervised-Multimodal-Learning-on-MIMIC-CXR
excerpt: 'We propose a novel multimodal VAE that enables multimodal capabilities by only soft-sharing of information between modalities.'
date: 2024-05-28
venue: 'ML4H Symposium at Neurips 2024'
paperurl: 'https://arxiv.org/abs/2411.10356'
citation: 'A Agostini, D Chopard, Y Meng, N Fortin, B Shahbaba, S Mandt, <b>TM Sutter</b> and JE Vogt (2024) &quot;Weakly-Supervised Multimodal Learning on MIMIC-CXR.&quot; <i>ML4H</i>.'
---
We conduct an in-depth evaluation of the newly proposed Multimodal Variational Mixture-of-Experts (MMVM) VAE on the challenging MIMIC-CXR dataset. Our analysis demonstrates that the MMVM VAE consistently outperforms other multimodal VAEs and fully supervised approaches, highlighting its strong potential for real-world medical applications.

[Download paper here](https://arxiv.org/abs/2411.10356)

Recommended citation: A Agostini, D Chopard, Y Meng, N Fortin, B Shahbaba, S Mandt, **TM Sutter** and JE Vogt. (2024) "Weakly-Supervised Multimodal Learning on MIMIC-CXR." <i>Ml4H</i>.

